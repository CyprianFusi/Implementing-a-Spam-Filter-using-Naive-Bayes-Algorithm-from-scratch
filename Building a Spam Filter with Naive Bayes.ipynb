{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Spam Filter with Naive Bayes Algorithm from scratch\n",
    "We shall train a **`Naive Bayes` classification model** which is based on  **multinomial Naive Bayes machine learning algorithm**. Then use the model to classify new messages as either **spam** or **non spam** or **ham**.\n",
    "\n",
    "**Our goal is to create a spam filter that classifies new messages with an accuracy greater than `80%`.** \n",
    "\n",
    "## The Dataset\n",
    "As training dataset, we shall use a dataset of **`5,572` SMS messages** that are already classified or labelled by humans. The dataset was put together by Tiago **A. Almeida** and **José María Gómez Hidalgo**, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) or from [Amazon](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). \n",
    "\n",
    "The data collection process is described in more details in the [authors papers](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/SMSSpamCollection', sep = '\\t', header = None, names = ['Label', 'SMS'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find the distribution of `spam` Vs `ham` in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>86.593683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>13.406317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      frequency  percentage\n",
       "ham        4825   86.593683\n",
       "spam        747   13.406317"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = data.Label.value_counts()\n",
    "\n",
    "label_count_df = pd.DataFrame.from_dict(dict(label_count), orient = 'index')\n",
    "label_count_df.rename(columns = {0: 'frequency'}, inplace = True)\n",
    "label_count_df.sort_values(by = 'frequency', ascending = False, inplace = True)\n",
    "label_count_df['percentage'] = label_count_df.frequency.apply(lambda x: (100 * x / label_count_df.frequency.sum()))\n",
    "label_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we are dealing hugely **imbalance dataset!** We have about **`87%` of non-spam** with only **`13%` of the dataset labelled as spam**. This poses a serious problem because the **model would tend to be bias towards non-spam** messages. We shall have to address the problem posed by imbalance data before training the model.\n",
    "\n",
    "## Training the model\n",
    "### Training and Test Set\n",
    "We're going to use **`80%`** of our dataset (`4,458` messages) for training, and **`20%`** (`1,114` messages) for testing. Here, we shall use `train_test_split` function from `scikit-learn` to split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Label', axis = 1)   # features / messages\n",
    "y = data.Label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find the distribution of spam Vs ham in both training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     86.53803\n",
       "spam    13.46197\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     86.816143\n",
       "spam    13.183857\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that the function `train_test_split(test_size = 0.20)` split the dataset as expected while preserving the proportions of `ham` vs `spam` in the original dataset.**\n",
    "\n",
    "### Letter Case and Punctuation\n",
    "The **Naive Bayes** algorithm will make the classification based on the probability that the message is **spam** or **not spam (ham)**. These probabilities are calculated as follows:\n",
    "\n",
    "$$P(Spam | w_1, w_2, ... w_n) \\propto P(Spam).\\prod\\limits_{i=1}^{n}P(w_i | Spam)$$\n",
    "\n",
    "$$P(Ham | w_1, w_2, ... w_n) \\propto P(Ham).\\prod\\limits_{i=1}^{n}P(w_i | Ham)$$\n",
    "\n",
    "To calculate $P(w_i | Spam)$ and $P(w_i | Ham)$ inside the formulas above, we need to use these equations:\n",
    "\n",
    "$$P(w_i | Spam) = \\frac{N_{w_{i|Spam}} + \\alpha}{N_{Spam} + \\alpha . N_{vocab}}$$\n",
    "\n",
    "$$P(w_i | Ham) = \\frac{N_{w_{i|Ham}} + \\alpha}{N_{Ham} + \\alpha . N_{vocab}}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $N_{w_{i|Spam}}$ = the number of times the word $w_i$ occurs in spam messages\n",
    "\n",
    "* $N_{w_{i|Ham}}$ = the number of times the word $w_i$ occurs in non-spam messages\n",
    "\n",
    "* $N_{Spam}$ = total number of words in spam messages\n",
    "\n",
    "* $N_{Ham}$ = total number of words in non-spam messages\n",
    "\n",
    "* $N_{vocab}$ = total number of words in the vocabulary\n",
    "\n",
    "* $\\alpha = 1$ is a smoothing parameter\n",
    "\n",
    "It's worth noting that these calculations make the naive assumption that **words in the text messages are statistically independent**. However, this is not true in real life. Words take context meaning in sentences. This context meaning is considered in **Natural Language Processing (NLP)** applications that use **word embeddings** like **Large Language Models (LLMs)**. An example of LLM application is **ChatGPT**. \n",
    "\n",
    "This ***naive*** assumption in the implementation of the algorithm leads to its name as **Naive Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary for the features\n",
    "The **vocabulary** is a set of **unique** words in the dataset.\n",
    "* let's create a list with all of the unique words that occur in the messages of our training set.\n",
    "\n",
    "### Data Cleaning\n",
    "Since computers can only process numerical data, we will have to transform the data to numerical format before training the model.\n",
    "\n",
    "* Let's begin the data cleaning process by removing the punctuation and bringing all the words to lower case.\n",
    "* Then transform every letter in every word to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>hi   where are you  we re at  and they re not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>if you r   home then come down within 5 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>when re you guys getting back  g said you were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>tell my  bad character which u dnt lik in me  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>i m leaving my house now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS\n",
       "1642  hi   where are you  we re at  and they re not ...\n",
       "2899        if you r   home then come down within 5 min\n",
       "480   when re you guys getting back  g said you were...\n",
       "3485  tell my  bad character which u dnt lik in me  ...\n",
       "157                         i m leaving my house now   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train.loc[:, 'SMS'] = X_train.SMS.apply(lambda x: re.sub('\\W', ' ', x))\n",
    "X_train.loc[:, 'SMS'] = X_train.SMS.str.lower()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>[hi, where, are, you, we, re, at, and, they, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>[if, you, r, home, then, come, down, within, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>[when, re, you, guys, getting, back, g, said, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>[tell, my, bad, character, which, u, dnt, lik,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>[i, m, leaving, my, house, now]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS\n",
       "1642  [hi, where, are, you, we, re, at, and, they, r...\n",
       "2899  [if, you, r, home, then, come, down, within, 5...\n",
       "480   [when, re, you, guys, getting, back, g, said, ...\n",
       "3485  [tell, my, bad, character, which, u, dnt, lik,...\n",
       "157                     [i, m, leaving, my, house, now]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[:, 'SMS'] = X_train.SMS.str.split()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabs list: 64063\n",
      "Length of unique vocabs: 7714\n"
     ]
    }
   ],
   "source": [
    "# keep only word with more than 1 characters in vocabs\n",
    "vocabulary = [word for sms in X_train.SMS for word in sms if len(word) > 1]\n",
    "print('Length of vocabs list:', len(vocabulary))\n",
    "vocabulary = list(set(vocabulary))\n",
    "print('Length of unique vocabs:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Final Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {word: [0] * len(X_train.SMS) for word in vocabulary}\n",
    "\n",
    "for idx, sms in enumerate(X_train.SMS):\n",
    "    for word in sms:\n",
    "        if word in vocabulary:\n",
    "            word_counts_per_sms[word][idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affection</th>\n",
       "      <th>letters</th>\n",
       "      <th>monkeespeople</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>snap</th>\n",
       "      <th>08717898035</th>\n",
       "      <th>9t</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>subs</th>\n",
       "      <th>pod</th>\n",
       "      <th>...</th>\n",
       "      <th>transaction</th>\n",
       "      <th>sac</th>\n",
       "      <th>laden</th>\n",
       "      <th>23g</th>\n",
       "      <th>married</th>\n",
       "      <th>watched</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>shudvetold</th>\n",
       "      <th>80182</th>\n",
       "      <th>irritation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   affection  letters  monkeespeople  ultimate  snap  08717898035  9t  \\\n",
       "0          0        0              0         0     0            0   0   \n",
       "1          0        0              0         0     0            0   0   \n",
       "2          0        0              0         0     0            0   0   \n",
       "3          0        0              0         0     0            0   0   \n",
       "4          0        0              0         0     0            0   0   \n",
       "\n",
       "   epsilon  subs  pod  ...  transaction  sac  laden  23g  married  watched  \\\n",
       "0        0     0    0  ...            0    0      0    0        0        0   \n",
       "1        0     0    0  ...            0    0      0    0        0        0   \n",
       "2        0     0    0  ...            0    0      0    0        0        0   \n",
       "3        0     0    0  ...            0    0      0    0        0        0   \n",
       "4        0     0    0  ...            0    0      0    0        0        0   \n",
       "\n",
       "   abdomen  shudvetold  80182  irritation  \n",
       "0        0           0      0           0  \n",
       "1        0           0      0           0  \n",
       "2        0           0      0           0  \n",
       "3        0           0      0           0  \n",
       "4        0           0      0           0  \n",
       "\n",
       "[5 rows x 7714 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_counts_df = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts_df = pd.DataFrame.from_dict(word_counts_per_sms, orient = 'index').T\n",
    "word_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Constants First\n",
    "Let's calculate the constant needed in the above probability equations. For example:\n",
    "\n",
    "* the probability of a message being a Spam is simply the number of Spams divided by the total number of messages.\n",
    "\n",
    "* the probability of a message not being a Spam is simply the number of Hams divided by the total number of messages.\n",
    "\n",
    "#### Using the training set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_messages = len(word_counts_df)    # len(X_train)\n",
    "N_vocab = len(vocabulary)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "n_spam = y_train.value_counts()['spam']        # number of spam messages\n",
    "n_ham = y_train.value_counts()['ham']          # number of ham messages\n",
    "P_spam = n_spam / N_messages                   # prior prob of spam\n",
    "P_ham = n_ham / N_messages                     # prior prob of ham\n",
    "\n",
    "print(P_spam + P_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Parameters\n",
    "The probability values that $P(w_i | Spam)$ and $P(w_i | Ham)$ will take are called **parameters**.\n",
    "\n",
    "Our vocabulary ffor the training dataset is of length **`7,753`** and for each word we need to calculate $P(w_i | Spam)$ for **Spam** and $P(w_i | Ham)$ for **non-Spam**. This means we shall have to calculated **`7,753 x 2 = 15,506` probabilities!!!** \n",
    "\n",
    "The fact that we calculate so many values (as constants) before even beginning the classification of new messages makes the **Naive Bayes algorithm very fast** (especially compared to other algorithms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating the spam and the ham messages in the training set into two different DataFrames\n",
    "To make our job easier going forward, we shall include the training Labels to our training features. We shall also include the word counts features into the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "      <th>affection</th>\n",
       "      <th>letters</th>\n",
       "      <th>monkeespeople</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>snap</th>\n",
       "      <th>08717898035</th>\n",
       "      <th>9t</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>...</th>\n",
       "      <th>transaction</th>\n",
       "      <th>sac</th>\n",
       "      <th>laden</th>\n",
       "      <th>23g</th>\n",
       "      <th>married</th>\n",
       "      <th>watched</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>shudvetold</th>\n",
       "      <th>80182</th>\n",
       "      <th>irritation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>[hi, where, are, you, we, re, at, and, they, r...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>[if, you, r, home, then, come, down, within, 5...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>[when, re, you, guys, getting, back, g, said, ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>[tell, my, bad, character, which, u, dnt, lik,...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>[i, m, leaving, my, house, now]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS Label  affection  \\\n",
       "1642  [hi, where, are, you, we, re, at, and, they, r...   ham        0.0   \n",
       "2899  [if, you, r, home, then, come, down, within, 5...   ham        0.0   \n",
       "480   [when, re, you, guys, getting, back, g, said, ...   ham        0.0   \n",
       "3485  [tell, my, bad, character, which, u, dnt, lik,...   ham        0.0   \n",
       "157                     [i, m, leaving, my, house, now]   ham        0.0   \n",
       "\n",
       "      letters  monkeespeople  ultimate  snap  08717898035   9t  epsilon  ...  \\\n",
       "1642      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "2899      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "480       0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "3485      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "157       0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "\n",
       "      transaction  sac  laden  23g  married  watched  abdomen  shudvetold  \\\n",
       "1642          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "2899          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "480           0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "3485          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "157           0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "\n",
       "      80182  irritation  \n",
       "1642    0.0         0.0  \n",
       "2899    0.0         0.0  \n",
       "480     0.0         0.0  \n",
       "3485    0.0         0.0  \n",
       "157     0.0         0.0  \n",
       "\n",
       "[5 rows x 7716 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([X_train, word_counts_df], axis = 1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating the `spam` and the `ham` messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "      <th>affection</th>\n",
       "      <th>letters</th>\n",
       "      <th>monkeespeople</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>snap</th>\n",
       "      <th>08717898035</th>\n",
       "      <th>9t</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>...</th>\n",
       "      <th>transaction</th>\n",
       "      <th>sac</th>\n",
       "      <th>laden</th>\n",
       "      <th>23g</th>\n",
       "      <th>married</th>\n",
       "      <th>watched</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>shudvetold</th>\n",
       "      <th>80182</th>\n",
       "      <th>irritation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>[camera, you, are, awarded, a, sipix, digital,...</td>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>[500, free, text, msgs, just, text, ok, to, 80...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>[you, have, won, as, a, valued, vodafone, cust...</td>\n",
       "      <td>spam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>[auction, round, 4, the, highest, bid, is, now...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>[bored, housewives, chat, n, date, now, 087175...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS Label  affection  \\\n",
       "5365  [camera, you, are, awarded, a, sipix, digital,...  spam        NaN   \n",
       "1625  [500, free, text, msgs, just, text, ok, to, 80...  spam        0.0   \n",
       "4845  [you, have, won, as, a, valued, vodafone, cust...  spam        NaN   \n",
       "3564  [auction, round, 4, the, highest, bid, is, now...  spam        0.0   \n",
       "3998  [bored, housewives, chat, n, date, now, 087175...  spam        0.0   \n",
       "\n",
       "      letters  monkeespeople  ultimate  snap  08717898035   9t  epsilon  ...  \\\n",
       "5365      NaN            NaN       NaN   NaN          NaN  NaN      NaN  ...   \n",
       "1625      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "4845      NaN            NaN       NaN   NaN          NaN  NaN      NaN  ...   \n",
       "3564      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "3998      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "\n",
       "      transaction  sac  laden  23g  married  watched  abdomen  shudvetold  \\\n",
       "5365          NaN  NaN    NaN  NaN      NaN      NaN      NaN         NaN   \n",
       "1625          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "4845          NaN  NaN    NaN  NaN      NaN      NaN      NaN         NaN   \n",
       "3564          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "3998          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "\n",
       "      80182  irritation  \n",
       "5365    NaN         NaN  \n",
       "1625    0.0         0.0  \n",
       "4845    NaN         NaN  \n",
       "3564    0.0         0.0  \n",
       "3998    0.0         0.0  \n",
       "\n",
       "[5 rows x 7716 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = X_train.loc[X_train.Label == 'spam']\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "      <th>affection</th>\n",
       "      <th>letters</th>\n",
       "      <th>monkeespeople</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>snap</th>\n",
       "      <th>08717898035</th>\n",
       "      <th>9t</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>...</th>\n",
       "      <th>transaction</th>\n",
       "      <th>sac</th>\n",
       "      <th>laden</th>\n",
       "      <th>23g</th>\n",
       "      <th>married</th>\n",
       "      <th>watched</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>shudvetold</th>\n",
       "      <th>80182</th>\n",
       "      <th>irritation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>[hi, where, are, you, we, re, at, and, they, r...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>[if, you, r, home, then, come, down, within, 5...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>[when, re, you, guys, getting, back, g, said, ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>[tell, my, bad, character, which, u, dnt, lik,...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>[i, m, leaving, my, house, now]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS Label  affection  \\\n",
       "1642  [hi, where, are, you, we, re, at, and, they, r...   ham        0.0   \n",
       "2899  [if, you, r, home, then, come, down, within, 5...   ham        0.0   \n",
       "480   [when, re, you, guys, getting, back, g, said, ...   ham        0.0   \n",
       "3485  [tell, my, bad, character, which, u, dnt, lik,...   ham        0.0   \n",
       "157                     [i, m, leaving, my, house, now]   ham        0.0   \n",
       "\n",
       "      letters  monkeespeople  ultimate  snap  08717898035   9t  epsilon  ...  \\\n",
       "1642      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "2899      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "480       0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "3485      0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "157       0.0            0.0       0.0   0.0          0.0  0.0      0.0  ...   \n",
       "\n",
       "      transaction  sac  laden  23g  married  watched  abdomen  shudvetold  \\\n",
       "1642          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "2899          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "480           0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "3485          0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "157           0.0  0.0    0.0  0.0      0.0      0.0      0.0         0.0   \n",
       "\n",
       "      80182  irritation  \n",
       "1642    0.0         0.0  \n",
       "2899    0.0         0.0  \n",
       "480     0.0         0.0  \n",
       "3485    0.0         0.0  \n",
       "157     0.0         0.0  \n",
       "\n",
       "[5 rows x 7716 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_df = X_train.loc[X_train.Label == 'ham']\n",
    "ham_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize two dictionaries that will hold the word counts used to calculate the parameters\n",
    "#### Counting the unique words and updating the dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dict = {}\n",
    "ham_dict = {}\n",
    "\n",
    "for sms in spam_df.SMS:\n",
    "    for word in sms:\n",
    "        if word not in spam_dict:\n",
    "            spam_dict[word] = 0\n",
    "        spam_dict[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of words in spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_spam = sum(spam_dict.values())\n",
    "N_w_spam = sum(value for key, value in spam_dict.items() if len(key) > 1)  # keep only word with more than 1 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sms in ham_df.SMS:\n",
    "    for word in sms:\n",
    "        if word not in ham_dict:\n",
    "            ham_dict[word] = 0\n",
    "        ham_dict[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of words in ham messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_ham = sum(ham_dict.values())\n",
    "N_w_ham = sum(value for key, value in ham_dict.items() if len(key) > 1)    # keep only word with more than 1 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wi_spam = {}\n",
    "p_wi_ham = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    p_wi_spam[word] = (spam_df[word].sum() + alpha)/(N_w_spam + alpha * N_vocab)\n",
    "    p_wi_ham[word] = (ham_df[word].sum() + alpha)/(N_w_ham + alpha * N_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying A New Message\n",
    "Helper function to classify messages as either **spam** or **ham**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = P_spam\n",
    "    p_ham_given_message = P_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_wi_spam:\n",
    "            p_spam_given_message *= p_wi_spam[word]\n",
    "        if word in p_wi_ham:\n",
    "            p_ham_given_message *= p_wi_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting our function to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 7.620825602825606e-29\n",
      "P(Ham|message): 4.775405553037237e-25\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "message = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "classify(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 6.912318244205037e-23\n",
      "P(Ham|message): 2.060362529863275e-19\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "message = \"Sounds good, Tom, then see u there\"\n",
    "classify(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the Spam Filter's Accuracy using the test dataset\n",
    "We are going to use the **`1,115`** messages we kept aside as testing dataset to evaluate out classifier. Every message in the test set is practically new from the perspective of the algorithm since the algorithm didn't see these during training.\n",
    "\n",
    "But we'll have to modify out classifier to output the predictions (spam or ham) alongside the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = P_spam\n",
    "    p_ham_given_message = P_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_wi_spam:\n",
    "            p_spam_given_message *= p_wi_spam[word]\n",
    "        if word in p_wi_ham:\n",
    "            p_ham_given_message *= p_wi_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'undecided'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>Havent.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS Label\n",
       "1078                       Yep, by the pretty sculpture   ham\n",
       "4028      Yes, princess. Are you going to make me moan?   ham\n",
       "958                          Welp apparently he retired   ham\n",
       "4642                                            Havent.   ham\n",
       "4674  I forgot 2 ask ü all smth.. There's a card on ...   ham"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Label'] = y_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>Havent.</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS Label Prediction\n",
       "1078                       Yep, by the pretty sculpture   ham        ham\n",
       "4028      Yes, princess. Are you going to make me moan?   ham        ham\n",
       "958                          Welp apparently he retired   ham        ham\n",
       "4642                                            Havent.   ham        ham\n",
       "4674  I forgot 2 ask ü all smth.. There's a card on ...   ham        ham"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Prediction'] = X_test.SMS.apply(classify_test_set)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Accuracy of the Classifier\n",
    "The accuracy is calculated as follows:\n",
    "\n",
    "$$Accuracy = \\frac{number\\space of\\space  correctly\\space  classified\\space  messages}{total\\space  number\\space  of\\space  classified\\space  messages}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier got 972 out of 1115 correct\n",
      "The classifier has an accuracy of  87.17%\n"
     ]
    }
   ],
   "source": [
    "num_correct = sum(X_test['Prediction'] == X_test['Label'])\n",
    "acc = num_correct / len(X_test)\n",
    "print(f'The classifier got {num_correct} out of {len(X_test)} correct')\n",
    "print(f'The classifier has an accuracy of {acc * 100: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wow! This looks great! Our goal was to obtain an accuracy of `80%` but we got `87%`! Our classifier is doing a great job!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Constants used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probability of getting a spam (P_spam):  0.13\n",
      "Prior Probability of not getting a spam (P_ham):  0.87\n",
      "Number of words in spam messages in dataset (N_w_spam):  14,012\n",
      "Number of words in non spam messages in dataset (N_w_ham):  50,051\n",
      "Number of unique words in vocabulary (N_vocab):  7,714\n",
      "Smoothing parameter (alpha):  1\n"
     ]
    }
   ],
   "source": [
    "print(f'Prior Probability of getting a spam (P_spam): {P_spam: .2f}')\n",
    "print(f'Prior Probability of not getting a spam (P_ham): {P_ham: .2f}')\n",
    "print(f'Number of words in spam messages in dataset (N_w_spam): {N_w_spam: ,}')\n",
    "print(f'Number of words in non spam messages in dataset (N_w_ham): {N_w_ham: ,}')\n",
    "print(f'Number of unique words in vocabulary (N_vocab): {N_vocab: ,}')\n",
    "print(f'Smoothing parameter (alpha): ', alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
